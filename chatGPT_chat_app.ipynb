{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJtsv5DFFXWR"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "# load and set our key\n",
        "openai.api_key = open(\"key.txt\", \"r\").read().strip(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QA6dV0OVFXWT"
      },
      "outputs": [],
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\", # this is \"ChatGPT\" $0.002 per 1k tokens\n",
        "  messages=[{\"role\": \"user\", \"content\": \"What is the circumference in km of the planet Earth?\"}]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBxcLTNVFXWU",
        "outputId": "5d9eb762-9b06-483f-ba8b-b1b03b787ceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"content\": \"\\n\\nThe circumference of the planet Earth in km is approximately 40,075 km.\",\n",
            "        \"role\": \"assistant\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1678044086,\n",
            "  \"id\": \"chatcmpl-6qoD8O1qGxluR2fct8hM9aSYDnqzU\",\n",
            "  \"model\": \"gpt-3.5-turbo-0301\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 18,\n",
            "    \"prompt_tokens\": 18,\n",
            "    \"total_tokens\": 36\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(completion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gcc9cR1fFXWV",
        "outputId": "b497684b-3f88-4883-e36f-cae020f287f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "The circumference of the planet Earth in km is approximately 40,075 km.\n"
          ]
        }
      ],
      "source": [
        "reply_content = completion.choices[0].message.content\n",
        "print(reply_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48SHFlNrFXWV",
        "outputId": "a5afc904-116f-484b-acfa-734223ef466e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User's input was:  What is the moon's circumference in km?\n"
          ]
        }
      ],
      "source": [
        "message_history = []\n",
        "# What is the moon's circumference in km?\n",
        "user_input = input(\"> \")\n",
        "print(\"User's input was: \", user_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88MyQOzXFXWW"
      },
      "outputs": [],
      "source": [
        "# Format user input for API\n",
        "message_history.append({\"role\": \"user\", \"content\": f\"{user_input}\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_F584ycaFXWW",
        "outputId": "d86392d4-d712-48bd-eb99-22556d594b51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "The moon's circumference is approximately 10,917 km.\n"
          ]
        }
      ],
      "source": [
        "# Query the API\n",
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=message_history\n",
        ")\n",
        "\n",
        "# Print the response:\n",
        "reply_content = completion.choices[0].message.content\n",
        "print(reply_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI8O5xapFXWX"
      },
      "outputs": [],
      "source": [
        "# append the history\n",
        "# note the use of the \"assistant\" role here. This is because we're feeding the model's response into context.\n",
        "message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_BPR44qFXWX",
        "outputId": "f27efa22-3e55-42ca-e346-22322d339a51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User's input was:  which moon is that in reference to?\n",
            "\n",
            "I'm sorry for the confusion. That circumference is for Earth's moon, also known as Luna.\n"
          ]
        }
      ],
      "source": [
        "# follow up query to make use of history\n",
        "user_input = input(\"> \") # which moon is that in reference to?\n",
        "print(\"User's input was: \", user_input)\n",
        "print()\n",
        "message_history.append({\"role\": \"user\", \"content\": f\"{user_input}\"})\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=message_history\n",
        ")\n",
        "\n",
        "reply_content = completion.choices[0].message.content\n",
        "print(reply_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOdyvR1TFXWX",
        "outputId": "ce0c0112-bf93-4d16-86ba-fd7ca4ee4017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User's input was:  Can I drink the water from a dehumidifier?\n",
            "\n",
            "\n",
            "As an AI language model, I cannot recommend that you drink water from a dehumidifier. Although dehumidifiers remove moisture from the air, the water collected can contain impurities and toxins that are harmful to human health. Also, dehumidifiers are not designed to produce potable water, and the water may contain bacteria, fungi, or other contaminants that might make you ill. It is always best to use a certified water source or filter the collected water before drinking it.\n",
            "\n",
            "User's input was:  How might we make it safe in an emergency to drink?\n",
            "In an emergency situation, it is essential to have access to safe drinking water. If you need water and there is no other option but to use water from a dehumidifier, here are some steps you can take to make it safer to drink:\n",
            "\n",
            "1. Check the water: Make sure the water is clean and clear. If the water is cloudy or has particles in it, do not drink it.\n",
            "\n",
            "2. Boil the water: Boiling the water can kill off any bacteria or viruses that may be present. Bring the water to a rolling boil, then let it cool down before drinking.\n",
            "\n",
            "3. Use a filter: A water filter can help remove impurities from the water. A portable water filter, such as a ceramic or carbon filter, can be useful in such situations.\n",
            "\n",
            "4. Add purification tablets or drops: Purification tablets or drops, such as iodine or chlorine, can kill off harmful microorganisms in the water. Follow the instructions provided by the manufacturer to ensure proper usage.\n",
            "\n",
            "It is always better to have clean and safe drinking water stored in advance, rather than relying on questionable sources during an emergency situation.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Combining everything\n",
        "message_history = []\n",
        "\n",
        "def chat(inp, role=\"user\"):\n",
        "    message_history.append({\"role\": role, \"content\": f\"{inp}\"})\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=message_history\n",
        "    )\n",
        "    reply_content = completion.choices[0].message.content\n",
        "    message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})\n",
        "    return reply_content\n",
        "\n",
        "for i in range(2):\n",
        "    user_input = input(\"> \")\n",
        "    print(\"User's input was: \", user_input)\n",
        "    print(chat(user_input))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtxhNQkGFXWY"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "openai.api_key = open(\"key.txt\", \"r\").read().strip(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeEyN2ZCFXWY"
      },
      "outputs": [],
      "source": [
        "message_history = [{\"role\": \"user\", \"content\": f\"You are a joke bot. I will specify the subject matter in my messages, and you will reply with a joke that includes the subjects I mention in my messages. Reply only with jokes to further input. If you understand, say OK.\"},\n",
        "                   {\"role\": \"assistant\", \"content\": f\"OK\"}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhfHNU8IFXWZ"
      },
      "outputs": [],
      "source": [
        "def predict(input):\n",
        "    # tokenize the new input sentence\n",
        "    message_history.append({\"role\": \"user\", \"content\": f\"{input}\"})\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=message_history\n",
        "    )\n",
        "    #Just the reply text\n",
        "    reply_content = completion.choices[0].message.content#.replace('```python', '<pre>').replace('```', '</pre>')\n",
        "    \n",
        "    message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"}) \n",
        "    \n",
        "    # get pairs of msg[\"content\"] from message history, skipping the pre-prompt:              here.\n",
        "    response = [(message_history[i][\"content\"], message_history[i+1][\"content\"]) for i in range(2, len(message_history)-1, 2)]  # convert to tuples of list\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8RvEiKlFXWZ"
      },
      "outputs": [],
      "source": [
        "# creates a new Blocks app and assigns it to the variable demo.\n",
        "with gr.Blocks() as demo: \n",
        "\n",
        "    # creates a new Chatbot instance and assigns it to the variable chatbot.\n",
        "    chatbot = gr.Chatbot() \n",
        "\n",
        "    # creates a new Row component, which is a container for other components.\n",
        "    with gr.Row(): \n",
        "        '''creates a new Textbox component, which is used to collect user input. \n",
        "        The show_label parameter is set to False to hide the label, \n",
        "        and the placeholder parameter is set'''\n",
        "        txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n",
        "    '''\n",
        "    sets the submit action of the Textbox to the predict function, \n",
        "    which takes the input from the Textbox, the chatbot instance, \n",
        "    and the state instance as arguments. \n",
        "    This function processes the input and generates a response from the chatbot, \n",
        "    which is displayed in the output area.'''\n",
        "    txt.submit(predict, txt, chatbot) # submit(function, input, output)\n",
        "    #txt.submit(lambda :\"\", None, txt)  #Sets submit action to lambda function that returns empty string \n",
        "\n",
        "    '''\n",
        "    sets the submit action of the Textbox to a JavaScript function that returns an empty string. \n",
        "    This line is equivalent to the commented out line above, but uses a different implementation. \n",
        "    The _js parameter is used to pass a JavaScript function to the submit method.'''\n",
        "    txt.submit(None, None, txt, _js=\"() => {''}\") # No function, no input to that function, submit action to textbox is a js function that returns empty string, so it clears immediately.\n",
        "         \n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaR2aNQ9FXWa"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "openai.api_key = open(\"key.txt\", \"r\").read().strip(\"\\n\")\n",
        "\n",
        "message_history = [{\"role\": \"user\", \"content\": f\"You are a joke bot. I will specify the subject matter in my messages, and you will reply with a joke that includes the subjects I mention in my messages. Reply only with jokes to further input. If you understand, say OK.\"},\n",
        "                   {\"role\": \"assistant\", \"content\": f\"OK\"}]\n",
        "\n",
        "def predict(input):\n",
        "    # tokenize the new input sentence\n",
        "    message_history.append({\"role\": \"user\", \"content\": f\"{input}\"})\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo\", #10x cheaper than davinci, and better. $0.002 per 1k tokens\n",
        "      messages=message_history\n",
        "    )\n",
        "    #Just the reply:\n",
        "    reply_content = completion.choices[0].message.content#.replace('```python', '<pre>').replace('```', '</pre>')\n",
        "\n",
        "    print(reply_content)\n",
        "    message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"}) \n",
        "    \n",
        "    # get pairs of msg[\"content\"] from message history, skipping the pre-prompt:              here.\n",
        "    response = [(message_history[i][\"content\"], message_history[i+1][\"content\"]) for i in range(2, len(message_history)-1, 2)]  # convert to tuples of list\n",
        "    return response\n",
        "\n",
        "# creates a new Blocks app and assigns it to the variable demo.\n",
        "with gr.Blocks() as demo: \n",
        "\n",
        "    # creates a new Chatbot instance and assigns it to the variable chatbot.\n",
        "    chatbot = gr.Chatbot() \n",
        "\n",
        "    # creates a new Row component, which is a container for other components.\n",
        "    with gr.Row(): \n",
        "        '''creates a new Textbox component, which is used to collect user input. \n",
        "        The show_label parameter is set to False to hide the label, \n",
        "        and the placeholder parameter is set'''\n",
        "        txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n",
        "    '''\n",
        "    sets the submit action of the Textbox to the predict function, \n",
        "    which takes the input from the Textbox, the chatbot instance, \n",
        "    and the state instance as arguments. \n",
        "    This function processes the input and generates a response from the chatbot, \n",
        "    which is displayed in the output area.'''\n",
        "    txt.submit(predict, txt, chatbot) # submit(function, input, output)\n",
        "    #txt.submit(lambda :\"\", None, txt)  #Sets submit action to lambda function that returns empty string \n",
        "\n",
        "    '''\n",
        "    sets the submit action of the Textbox to a JavaScript function that returns an empty string. \n",
        "    This line is equivalent to the commented out line above, but uses a different implementation. \n",
        "    The _js parameter is used to pass a JavaScript function to the submit method.'''\n",
        "    txt.submit(None, None, txt, _js=\"() => {''}\") # No function, no input to that function, submit action to textbox is a js function that returns empty string, so it clears immediately.\n",
        "         \n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxJ8E9P2FXWa"
      },
      "source": [
        "From here, we can open the app:\n",
        "\n",
        "```\n",
        "$ python3 gradio-joke.py \n",
        "Running on local URL:  http://127.0.0.1:7860\n",
        "\n",
        "To create a public link, set `share=True` in `launch()`.\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}